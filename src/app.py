# src/app.py
from flask import Flask, render_template, request, jsonify, send_file
import pickle
import re
import nltk
import pandas as pd
import json
import os
import sys
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer
from datetime import datetime
import io

# Download NLTK data
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords', quiet=True)
    nltk.download('wordnet', quiet=True)

# Get the directory where app.py is located (src folder)
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# Get project root (parent of src)
PROJECT_ROOT = os.path.dirname(BASE_DIR)

# Configure Flask with explicit template and static folders
app = Flask(__name__, 
            template_folder=os.path.join(BASE_DIR, 'templates'),
            static_folder=os.path.join(BASE_DIR, 'static'))

app.config['SECRET_KEY'] = 'your-secret-key-here'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max

class TextPreprocessor:
    def __init__(self):
        self.lemmatizer = WordNetLemmatizer()
        self.stop_words = set(stopwords.words("english"))
        self.punct = r"""!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~"""

    def clean_text(self, text: str) -> str:
        if not isinstance(text, str) or not text.strip():
            return ""
        
        text = text.strip().lower()
        text = re.sub(r"https?://\S+|www\.\S+", "", text)
        text = text.translate(str.maketrans("", "", self.punct))
        text = "".join([i for i in text if not i.isdigit()])
        text = " ".join([w for w in text.split() if w not in self.stop_words])
        text = " ".join([self.lemmatizer.lemmatize(w) for w in text.split()])
        
        return text.strip()

# Initialize preprocessor
preprocessor = TextPreprocessor()

def get_path(relative_path):
    """Get absolute path from project root"""
    return os.path.join(PROJECT_ROOT, relative_path)

# Load model and vectorizer
def load_model_and_vectorizer():
    try:
        model_path = get_path("models/model.pkl")
        print(f"Loading model from: {model_path}")
        
        with open(model_path, "rb") as f:
            model = pickle.load(f)
        
        # Recreate vectorizer
        train_path = get_path("data/processed/train_processed.csv")
        print(f"Loading training data from: {train_path}")
        
        train_df = pd.read_csv(train_path)
        vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1, 2))
        vectorizer.fit(train_df["content"].fillna(""))
        
        print("‚úÖ Model and vectorizer loaded successfully")
        return model, vectorizer
    except Exception as e:
        print(f"‚ùå Error loading model: {e}")
        return None, None

model, vectorizer = load_model_and_vectorizer()

# Load metrics
def load_metrics():
    try:
        metrics_path = get_path("evaluation/metrics.json")
        with open(metrics_path, "r") as f:
            return json.load(f)
    except Exception as e:
        print(f"‚ö†Ô∏è Could not load metrics: {e}")
        return {
            "accuracy": 0.85,
            "precision": 0.84,
            "recall": 0.86,
            "f1_score": 0.85,
            "auc": 0.91
        }

# Routes
@app.route('/')
def index():
    """Home page with single text analysis"""
    metrics = load_metrics()
    return render_template('index.html', metrics=metrics)

@app.route('/batch')
def batch():
    """Batch analysis page"""
    return render_template('batch.html')

@app.route('/metrics')
def metrics_page():
    """Model metrics page"""
    metrics = load_metrics()
    cm_path = get_path("evaluation/confusion_matrix.png")
    has_cm = os.path.exists(cm_path)
    return render_template('metrics.html', metrics=metrics, has_cm=has_cm)

@app.route('/api/predict', methods=['POST'])
def predict():
    """API endpoint for single text prediction"""
    try:
        data = request.json
        text = data.get('text', '').strip()
        
        if not text:
            return jsonify({'error': 'No text provided'}), 400
        
        if model is None or vectorizer is None:
            return jsonify({'error': 'Model not loaded'}), 500
        
        # Preprocess
        cleaned_text = preprocessor.clean_text(text)
        
        if not cleaned_text:
            return jsonify({'error': 'Text is empty after preprocessing'}), 400
        
        # Vectorize and predict
        text_vector = vectorizer.transform([cleaned_text])
        prediction = model.predict(text_vector)[0]
        probability = model.predict_proba(text_vector)[0]
        
        result = {
            'sentiment': 'happy' if prediction == 1 else 'sad',
            'sentiment_label': 'üòä Happy' if prediction == 1 else 'üò¢ Sad',
            'emoji': 'üòä' if prediction == 1 else 'üò¢',
            'confidence': float(probability[prediction] * 100),
            'probabilities': {
                'sad': float(probability[0] * 100),
                'happy': float(probability[1] * 100)
            },
            'cleaned_text': cleaned_text,
            'original_text': text,
            'word_count': len(text.split()),
            'cleaned_word_count': len(cleaned_text.split()),
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/predict-batch', methods=['POST'])
def predict_batch():
    """API endpoint for batch prediction"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'No file uploaded'}), 400
        
        file = request.files['file']
        
        if file.filename == '':
            return jsonify({'error': 'No file selected'}), 400
        
        if not file.filename.endswith('.csv'):
            return jsonify({'error': 'Only CSV files are allowed'}), 400
        
        # Read CSV
        df = pd.read_csv(file)
        
        if 'text' not in df.columns:
            return jsonify({'error': 'CSV must have a "text" column'}), 400
        
        results = []
        
        for idx, text in enumerate(df['text']):
            try:
                if pd.isna(text) or not str(text).strip():
                    results.append({
                        'row': idx + 1,
                        'original_text': '',
                        'error': 'Empty text'
                    })
                    continue
                
                text = str(text)
                cleaned_text = preprocessor.clean_text(text)
                
                if not cleaned_text:
                    results.append({
                        'row': idx + 1,
                        'original_text': text[:100] + '...' if len(text) > 100 else text,
                        'error': 'Text empty after preprocessing'
                    })
                    continue
                
                text_vector = vectorizer.transform([cleaned_text])
                prediction = model.predict(text_vector)[0]
                probability = model.predict_proba(text_vector)[0]
                
                results.append({
                    'row': idx + 1,
                    'original_text': text[:100] + '...' if len(text) > 100 else text,
                    'sentiment': 'happy' if prediction == 1 else 'sad',
                    'sentiment_label': 'üòä Happy' if prediction == 1 else 'üò¢ Sad',
                    'confidence': round(probability[prediction] * 100, 2),
                    'happy_prob': round(probability[1] * 100, 2),
                    'sad_prob': round(probability[0] * 100, 2)
                })
                
            except Exception as e:
                results.append({
                    'row': idx + 1,
                    'original_text': text[:100] if isinstance(text, str) else '',
                    'error': str(e)
                })
        
        # Calculate summary
        valid_results = [r for r in results if 'error' not in r]
        happy_count = sum(1 for r in valid_results if r['sentiment'] == 'happy')
        sad_count = sum(1 for r in valid_results if r['sentiment'] == 'sad')
        
        summary = {
            'total': len(results),
            'successful': len(valid_results),
            'failed': len(results) - len(valid_results),
            'happy_count': happy_count,
            'sad_count': sad_count,
            'happy_percentage': round((happy_count / len(valid_results) * 100) if valid_results else 0, 2),
            'sad_percentage': round((sad_count / len(valid_results) * 100) if valid_results else 0, 2)
        }
        
        return jsonify({
            'results': results,
            'summary': summary
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/download-results', methods=['POST'])
def download_results():
    """Download batch results as CSV"""
    try:
        data = request.json
        results = data.get('results', [])
        
        if not results:
            return jsonify({'error': 'No results to download'}), 400
        
        # Create DataFrame
        df = pd.DataFrame(results)
        
        # Create CSV in memory
        output = io.StringIO()
        df.to_csv(output, index=False)
        output.seek(0)
        
        return send_file(
            io.BytesIO(output.getvalue().encode()),
            mimetype='text/csv',
            as_attachment=True,
            download_name=f'sentiment_results_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
        )
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/metrics')
def get_metrics():
    """Get model metrics as JSON"""
    return jsonify(load_metrics())

@app.route('/confusion-matrix')
def confusion_matrix_image():
    """Serve confusion matrix image"""
    try:
        cm_path = get_path('evaluation/confusion_matrix.png')
        return send_file(cm_path, mimetype='image/png')
    except:
        return "Confusion matrix not found", 404

@app.errorhandler(404)
def not_found(e):
    metrics = load_metrics()
    return render_template('index.html', metrics=metrics), 404

@app.errorhandler(500)
def server_error(e):
    return jsonify({'error': 'Internal server error'}), 500

if __name__ == '__main__':
    print("=" * 50)
    print("üöÄ Starting Flask Application")
    print("=" * 50)
    print(f"üìÅ Base Directory: {BASE_DIR}")
    print(f"üìÅ Project Root: {PROJECT_ROOT}")
    print(f"üìÅ Templates Folder: {os.path.join(BASE_DIR, 'templates')}")
    print(f"üìÅ Static Folder: {os.path.join(BASE_DIR, 'static')}")
    print("=" * 50)
    print("üåê Access the app at: http://localhost:5001")
    print("=" * 50)
    
    app.run(debug=True, host='0.0.0.0', port=5001)